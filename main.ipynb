{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ffd401a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from share import *\n",
    "from utils import *\n",
    "from hypOpt import *\n",
    "from plot import *\n",
    "import os\n",
    "import psutil\n",
    "import platform\n",
    "import time\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c70ee385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Versions:\n",
      "Python: 3.10.18\n",
      "PyTorch: 2.5.1\n",
      "GPyTorch: 1.14\n",
      "\n",
      "üöÄ GPU Info:\n",
      "CUDA available: False\n",
      "\n",
      "üßÆ CPU Info:\n",
      "Processor: Intel64 Family 6 Model 151 Stepping 2, GenuineIntel\n",
      "Cores (physical): 12\n",
      "Cores (logical): 20\n",
      "\n",
      "üß† RAM Info:\n",
      "Total: 15.77 GB\n",
      "Available: 9.14 GB\n",
      "\n",
      "‚öôÔ∏è CUDA Toolkit Version:\n",
      "nvcc not found\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "seed = 1\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# üì¶ Version Info\n",
    "print(\"üì¶ Versions:\")\n",
    "print(f\"Python: {platform.python_version()}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"GPyTorch: {gpytorch.__version__}\")\n",
    "\n",
    "# üöÄ GPU Info\n",
    "print(\"\\nüöÄ GPU Info:\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA available: True\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"  [{i}] {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"CUDA available: False\")\n",
    "\n",
    "# üßÆ CPU Info\n",
    "print(\"\\nüßÆ CPU Info:\")\n",
    "print(f\"Processor: {platform.processor()}\")\n",
    "print(f\"Cores (physical): {psutil.cpu_count(logical=False)}\")\n",
    "print(f\"Cores (logical): {psutil.cpu_count(logical=True)}\")\n",
    "\n",
    "# üß† RAM Info\n",
    "print(\"\\nüß† RAM Info:\")\n",
    "vmem = psutil.virtual_memory()\n",
    "print(f\"Total: {vmem.total / (1024**3):.2f} GB\")\n",
    "print(f\"Available: {vmem.available / (1024**3):.2f} GB\")\n",
    "\n",
    "# ‚öôÔ∏è CUDA Toolkit Version (if available)\n",
    "print(\"\\n‚öôÔ∏è CUDA Toolkit Version:\")\n",
    "try:\n",
    "    output = os.popen(\"nvcc --version\").read()\n",
    "    print(output if output else \"nvcc not found\")\n",
    "except:\n",
    "    print(\"Could not retrieve CUDA version\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073e66b7",
   "metadata": {},
   "source": [
    "# 5.1 Evaluation of hyperparameter optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366c3c0d",
   "metadata": {},
   "source": [
    "### 1. Set configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61556190",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"M\"    : 10,               # Number of agents  \n",
    "    \"Ni\"   : 4,               # Number of neighbors\n",
    "    \"q\"    : 2**40,           # Modulus\n",
    "    \"Lw\"   : 1/40,            # Scale factor\n",
    "    \"Lz\"   : 1/2**20,         # Scale factor\n",
    "    \"Thyp\" : 30,              # Optimization step for hyperparameter optimization\n",
    "    \"eta\"  : 0.1,             # Learning rate\n",
    "    \"decay\": 0.99,            # Decay rate\n",
    "    \"T\"    : 20               # Optimization step for main Protocol\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197d2559",
   "metadata": {},
   "source": [
    "### 2. Network topology\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df95b482",
   "metadata": {},
   "source": [
    "##### a) Graph generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4677e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# --- Generate undirected, connected Ni-regular graph with M agents \n",
    "### Every agent has Ni number of neighbors\n",
    "assert config[\"Ni\"] < config[\"M\"] and config[\"Ni\"] >= 1 and (config[\"M\"] * config[\"Ni\"]) % 2 == 0, \"Invalid Ni-regular graph\"\n",
    "\n",
    "connected = False\n",
    "while not connected:\n",
    "    G = nx.random_regular_graph(d=config[\"Ni\"], n=config[\"M\"]) \n",
    "    connected = nx.is_connected(G)\n",
    "\n",
    "### (Optional) Visualize the graph\n",
    "# nx.draw(G, with_labels=True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41951c39",
   "metadata": {},
   "source": [
    "##### b) Define Metropolis weight "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34fc1a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define Metropolis weights\n",
    "C = 2\n",
    "W = np.zeros((config[\"M\"], config[\"M\"]))\n",
    "for i in range(config[\"M\"]):\n",
    "    d_i = G.degree[i]\n",
    "    for j in G.neighbors(i):\n",
    "        d_j = G.degree[j]\n",
    "        W[i, j] = 1 / (C * (1 + max(d_i, d_j)))\n",
    "    W[i, i] = 1 - np.sum(W[i])  # self-weight\n",
    "\n",
    "config[\"Wbar\"] = W/config[\"Lw\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce39af0c",
   "metadata": {},
   "source": [
    "### 3. Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3ca7d2",
   "metadata": {},
   "source": [
    "##### a) SARCOS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0a6faed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train x size: (44484, 21)\n",
      "Test x size: (4449, 21)\n",
      "Train y size: (44484, 7)\n",
      "Test y size: (4449, 7)\n"
     ]
    }
   ],
   "source": [
    "# Training data: 44,484\n",
    "# Test data: 4,449\n",
    "# 21 inputs\n",
    "# 7 outputs\n",
    "\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# --- Load data\n",
    "train_data = loadmat('data/sarcos_inv.mat')\n",
    "full_train = train_data['sarcos_inv']  # shape: (44484, 28)\n",
    "test_data = loadmat('data/sarcos_inv_test.mat')\n",
    "full_test = test_data['sarcos_inv_test']  # shape: (4449, 28)\n",
    "\n",
    "# --- Split into inputs and outputs\n",
    "sarcos_X_train = full_train[:, :21]\n",
    "sarcos_Y_train = full_train[:, 21:]\n",
    "\n",
    "sarcos_X_test = full_test[:, :21]\n",
    "sarcos_Y_test = full_test[:, 21:]\n",
    "\n",
    "print(\"Train x size:\", sarcos_X_train.shape)\n",
    "print(\"Test x size:\", sarcos_X_test.shape)\n",
    "print(\"Train y size:\", sarcos_Y_train.shape)\n",
    "print(\"Test y size:\", sarcos_Y_test.shape)\n",
    "\n",
    "# --- Output dimension\n",
    "config[\"k\"] = sarcos_Y_train.shape[1]\n",
    "\n",
    "# --- Convert to torch tensors\n",
    "sarcos_X_train_t = torch.tensor(sarcos_X_train, dtype=torch.float32)\n",
    "sarcos_Y_train_t = torch.tensor(sarcos_Y_train, dtype=torch.float32)\n",
    "sarcos_X_test_t = torch.tensor(sarcos_X_test, dtype=torch.float32)\n",
    "sarcos_Y_test_t = torch.tensor(sarcos_Y_test, dtype=torch.float32)\n",
    "\n",
    "# --- Shuffle training data\n",
    "sarcos_perm = torch.randperm(sarcos_X_train_t.size(0))\n",
    "sarcos_X_train_shuffled = sarcos_X_train_t[sarcos_perm]\n",
    "sarcos_Y_train_shuffled = sarcos_Y_train_t[sarcos_perm]\n",
    "\n",
    "# --- Split into M parts for agents\n",
    "sarcos_X_parts = [part.to(device) for part in torch.tensor_split(sarcos_X_train_shuffled, config[\"M\"])]\n",
    "sarcos_Y_parts = [part.to(device) for part in torch.tensor_split(sarcos_Y_train_shuffled, config[\"M\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb30897f",
   "metadata": {},
   "source": [
    "##### b) Diabetes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27c593fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train x size: (353, 10)\n",
      "Test x size: (89, 10)\n",
      "Train y size: (353,)\n",
      "Test y size: (89,)\n"
     ]
    }
   ],
   "source": [
    "# --- Load data\n",
    "diabetes = load_diabetes()\n",
    "diab_X = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)\n",
    "diab_Y = pd.Series(diabetes.target, name='target')\n",
    "\n",
    "# --- Split into train/test points (80/20)\n",
    "diab_X_train, diab_X_test, diab_Y_train, diab_Y_test = train_test_split(\n",
    "    diab_X, diab_Y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# --- Number of test points\n",
    "diab_ntest = diab_X_test.shape[0]  \n",
    "\n",
    "print(\"Train x size:\", diab_X_train.shape)\n",
    "print(\"Test x size:\", diab_X_test.shape)\n",
    "print(\"Train y size:\", diab_Y_train.shape)\n",
    "print(\"Test y size:\", diab_Y_test.shape)\n",
    "\n",
    "# --- Convert to torch tensors \n",
    "diab_X_train_t = torch.tensor(diab_X_train.values, dtype=torch.float32)\n",
    "diab_Y_train_t = torch.tensor(diab_Y_train.values, dtype=torch.float32)\n",
    "diab_X_test_t = torch.tensor(diab_X_test.values, dtype=torch.float32)\n",
    "diab_Y_test_t = torch.tensor(diab_Y_test.values, dtype=torch.float32)\n",
    "\n",
    "# --- Shuffle training data\n",
    "diab_perm = torch.randperm(diab_X_train_t.size(0))\n",
    "diab_X_train_shuffled = diab_X_train_t[diab_perm]\n",
    "diab_Y_train_shuffled = diab_Y_train_t[diab_perm]\n",
    "\n",
    "# --- Split into M parts for agents\n",
    "diab_X_parts = [x.to(device) for x in torch.tensor_split(diab_X_train_shuffled, config[\"M\"])]\n",
    "diab_Y_parts = [y.to(device) for y in torch.tensor_split(diab_Y_train_shuffled, config[\"M\"])]\n",
    "\n",
    "# --- Make y_parts 2D for GP compatibility\n",
    "diab_Y_parts = [y.unsqueeze(-1) for y in diab_Y_parts]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba291253",
   "metadata": {},
   "source": [
    "### 4. Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc9d748",
   "metadata": {},
   "source": [
    "##### a) SARCOS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8980025e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Hyperparameter optimization\n",
    "### Comment this section out to load pre-trained hyperparameter\n",
    "sarcos_scales = [10.0, 10.0, 10.0]\n",
    "sarcos_models_all, sarcos_likelihoods_all, sarcos_history_all, sarcos_loss_sum_all = hyperparameter_optimization(sarcos_X_parts, sarcos_Y_parts, G, config, sarcos_scales, device)\n",
    "\n",
    "for i in range(config[\"M\"]):\n",
    "    for d in range(config[\"k\"]):\n",
    "        sarcos_models_all[i][d] = sarcos_models_all[i][d].to(device)\n",
    "        sarcos_likelihoods_all[i][d] = sarcos_likelihoods_all[i][d].to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8aa0490",
   "metadata": {},
   "source": [
    "##### b) Diabetes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2cd9546",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\OneDrive\\ÏïîÌò∏\\2025\\2025 AAAI Distributed GPR\\Privacy-preservng-dGPR\\hypOpt.py:209: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(consensus_result[i, :], dtype=torch.float32, device=device)\n"
     ]
    }
   ],
   "source": [
    "# --- Hyperparameter optimization\n",
    "### Comment this section out to load pre-trained hyperparameter\n",
    "diab_scales = [10.0, 10.0, 20.0]\n",
    "diab_models, diab_likelihoods, diab_history, diab_loss_sum, diab_elapsed = hyperparameter_optimization_1D(diab_X_parts, diab_Y_parts, G, config, diab_scales, device)\n",
    "for i in range(config[\"M\"]):\n",
    "    diab_models[i] = diab_models[i].to(device)\n",
    "    diab_likelihoods[i] = diab_likelihoods[i].to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f2923c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- change sarcos_history_all[0] to sarcos_history_all[i] to see the result for i-th output dimension\n",
    "plot_hyperparameter(sarcos_history_all[0], diab_history, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42aeaeb",
   "metadata": {},
   "source": [
    "# 5.2 Accuracy analysis: Iterations and scale factor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88562ea7",
   "metadata": {},
   "source": [
    "### 1. Run standard distributed GPR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89287005",
   "metadata": {},
   "source": [
    "##### a) SARCOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f2ca37",
   "metadata": {},
   "outputs": [],
   "source": [
    "sarcos_test_samples = 4449 # desired number of test points (less than 4449)\n",
    "\n",
    "# Select the test_samples\n",
    "sarcos_X_test_red = sarcos_X_test[:sarcos_test_samples, :]\n",
    "sarcos_Y_test_red = sarcos_Y_test[:sarcos_test_samples, :]\n",
    "\n",
    "# Convert to torch tensors \n",
    "sarcos_X_test_t_red = torch.tensor(sarcos_X_test_red, dtype=torch.float32)\n",
    "sarcos_Y_test_t_red = torch.tensor(sarcos_Y_test_red, dtype=torch.float32)\n",
    "\n",
    "# sarcos_means[i][j]: predicted mean from agent i for output dimension j\n",
    "# sarcos_variances[i][j]: predicted variance from agent i for output dimension j\n",
    "sarcos_means     = [[None for _ in range(config[\"k\"])] for _ in range(config[\"M\"])]\n",
    "sarcos_variances = [[None for _ in range(config[\"k\"])] for _ in range(config[\"M\"])]\n",
    "\n",
    "num_repeats = 20\n",
    "times = []\n",
    "\n",
    "for _ in range(num_repeats):\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i in range(config[\"M\"]):  # iterate over agents\n",
    "        for j in range(config[\"k\"]):  # iterate over output dimensions\n",
    "            model = sarcos_models_all[i][j]\n",
    "            likelihood = sarcos_likelihoods_all[i][j]\n",
    "            model.eval()\n",
    "            likelihood.eval()\n",
    "            with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "                pred = likelihood(model(sarcos_X_test_t_red))\n",
    "                sarcos_means[i][j] = pred.mean       # shape: (N_test,)\n",
    "                sarcos_variances[i][j] = pred.variance  # shape: (N_test,)\n",
    "\n",
    "    end_time = time.time()\n",
    "    times.append(end_time - start_time)\n",
    "\n",
    "mean_time = np.mean(times)\n",
    "std_time = np.std(times)\n",
    "\n",
    "print(f\"Average time over {num_repeats} runs for local prediction: {mean_time:.6f} ¬± {std_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25449d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Compute POE mean and variances\n",
    "sarcos_poe_means = torch.zeros(sarcos_test_samples, config[\"k\"], device=device)\n",
    "sarcos_poe_vars  = torch.zeros(sarcos_test_samples, config[\"k\"], device=device)\n",
    "\n",
    "num_repeats = 20\n",
    "times = []\n",
    "\n",
    "for _ in range(num_repeats):\n",
    "    start_time = time.time()\n",
    "\n",
    "    for j in range(config[\"k\"]):  # loop over output dimensions\n",
    "        all_means = []  # shape: (M, N_test)\n",
    "        all_vars  = []  # shape: (M, N_test)\n",
    "\n",
    "        for i in range(config[\"M\"]):  # loop over agents\n",
    "            m = sarcos_means[i][j]     # tensor of shape (N_test,)\n",
    "            v = sarcos_variances[i][j] # tensor of shape (N_test,)\n",
    "            all_means.append(m.unsqueeze(0))  # shape (1, N_test)\n",
    "            all_vars.append(v.unsqueeze(0))\n",
    "\n",
    "        all_means = torch.cat(all_means, dim=0)  # shape: (M, N_test)\n",
    "        all_vars = torch.cat(all_vars, dim=0)    # shape: (M, N_test)\n",
    "\n",
    "        inv_vars = 1.0 / all_vars\n",
    "        poe_vars_j = 1.0 / inv_vars.sum(dim=0)\n",
    "        poe_means_j = poe_vars_j * (inv_vars * all_means).sum(dim=0)\n",
    "\n",
    "        sarcos_poe_means[:, j] = poe_means_j\n",
    "        sarcos_poe_vars[:, j]  = poe_vars_j\n",
    "\n",
    "    end_time = time.time()\n",
    "    times.append(end_time - start_time)\n",
    "\n",
    "mean_time = np.mean(times)\n",
    "std_time = np.std(times)\n",
    "\n",
    "print(f\"Average time over {num_repeats} runs for PoE aggregation: {mean_time:.6f} ¬± {std_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8431b86",
   "metadata": {},
   "source": [
    "##### b) Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57b4fa32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time over 20 runs for local prediction: 0.010864 ¬± 0.006269 seconds\n"
     ]
    }
   ],
   "source": [
    "diab_means = [None for _ in range(config[\"M\"])]\n",
    "diab_vars  = [None for _ in range(config[\"M\"])]\n",
    "\n",
    "diab_X_test_t = diab_X_test_t.to(device)\n",
    "\n",
    "num_repeats = 20\n",
    "times = []\n",
    "\n",
    "for _ in range(num_repeats):\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i in range(config[\"M\"]):\n",
    "        model = diab_models[i]\n",
    "        likelihood = diab_likelihoods[i]\n",
    "        model.eval()\n",
    "        likelihood.eval()\n",
    "\n",
    "        with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "            pred = likelihood(model(diab_X_test_t))\n",
    "            diab_means[i] = pred.mean       # shape: (N_test,)\n",
    "            diab_vars[i]  = pred.variance   # shape: (N_test,)\n",
    "\n",
    "    end_time = time.time()\n",
    "    times.append(end_time - start_time)\n",
    "\n",
    "mean_time = np.mean(times)\n",
    "std_time = np.std(times)\n",
    "\n",
    "print(f\"Average time over {num_repeats} runs for local prediction: {mean_time:.6f} ¬± {std_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9aa9097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time over 20 runs for PoE aggregation: 0.000072 ¬± 0.000312 seconds\n"
     ]
    }
   ],
   "source": [
    "# --- Compute PoE mean and variances for Diab dataset\n",
    "diab_poe_means = torch.zeros_like(diab_means[0], device=device)  # shape: (N_test,)\n",
    "diab_poe_vars  = torch.zeros_like(diab_vars[0], device=device)   # shape: (N_test,)\n",
    "\n",
    "diab_means_tensor = torch.stack(diab_means, dim=0).to(device)  # shape: (M, N_test)\n",
    "diab_vars_tensor  = torch.stack(diab_vars, dim=0).to(device)   # shape: (M, N_test)\n",
    "\n",
    "num_repeats = 20\n",
    "times = []\n",
    "\n",
    "for _ in range(num_repeats):\n",
    "    start_time = time.time()\n",
    "\n",
    "    all_means = diab_means_tensor  # shape: (M, N_test)\n",
    "    all_vars  = diab_vars_tensor   # shape: (M, N_test)\n",
    "\n",
    "    inv_vars = 1.0 / all_vars\n",
    "    poe_vars = 1.0 / inv_vars.sum(dim=0)                # shape: (N_test,)\n",
    "    poe_means = poe_vars * (inv_vars * all_means).sum(dim=0)  # shape: (N_test,)\n",
    "\n",
    "    diab_poe_means[:] = poe_means\n",
    "    diab_poe_vars[:]  = poe_vars\n",
    "\n",
    "    end_time = time.time()\n",
    "    times.append(end_time - start_time)\n",
    "\n",
    "mean_time = np.mean(times)\n",
    "std_time = np.std(times)\n",
    "\n",
    "print(f\"Average time over {num_repeats} runs for PoE aggregation: {mean_time:.6f} ¬± {std_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b589d7f",
   "metadata": {},
   "source": [
    "### 2. Run main protocol by varying scale factor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d8f756",
   "metadata": {},
   "source": [
    "### a) SARCOS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02993885",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lz_values = [10000]\n",
    "# Lz_values = [1,100,10000]\n",
    "num_Lz = len(Lz_values)\n",
    "num_repeats = 20\n",
    "times = []\n",
    "\n",
    "for repeat in range(num_repeats):\n",
    "    print(f\"\\n=== Run {repeat + 1}/{num_repeats} ===\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Allocate storage per run (could also preallocate once outside if reused)\n",
    "    sarcos_pppoe_means = torch.zeros((num_Lz, config[\"T\"]+1, sarcos_test_samples, config[\"k\"], config[\"M\"]), device=device)\n",
    "    sarcos_pppoe_vars  = torch.zeros((num_Lz, config[\"T\"]+1, sarcos_test_samples, config[\"k\"], config[\"M\"]), device=device)\n",
    "\n",
    "    for lz_idx, Lz in enumerate(Lz_values):\n",
    "        print(f\"Running consensus with Lz = 1/{Lz}\")\n",
    "        config[\"Lz\"] = 1.0 / Lz\n",
    "\n",
    "        all_means = torch.stack([\n",
    "            torch.stack([sarcos_means[m][j].to(device) for j in range(config[\"k\"])])\n",
    "            for m in range(config[\"M\"])\n",
    "        ]).permute(0, 2, 1) \n",
    "\n",
    "        all_vars = torch.stack([\n",
    "            torch.stack([sarcos_variances[m][j].to(device) for j in range(config[\"k\"])])\n",
    "            for m in range(config[\"M\"])\n",
    "        ]).permute(0, 2, 1) \n",
    "\n",
    "        weighted_means = all_means / all_vars\n",
    "        precisions = 1.0 / all_vars\n",
    "        weighted_means *= config[\"M\"]\n",
    "        precisions *= config[\"M\"]\n",
    "        combined = np.stack([weighted_means, precisions], axis=-1)\n",
    "        z_combined = combined.reshape(config[\"M\"], -1).cpu().numpy()\n",
    "\n",
    "        consensus_history = privacy_preserving_avg_consensus(z_combined, G, config, config[\"T\"]+1, device)\n",
    "\n",
    "        for t in range(config[\"T\"]+1):\n",
    "            step_t = consensus_history[t]\n",
    "            step_t_reshaped = step_t.reshape(config[\"M\"], sarcos_test_samples, config[\"k\"], 2)\n",
    "\n",
    "            means = torch.tensor(step_t_reshaped[:, :, :, 0], device=device) / torch.tensor(step_t_reshaped[:, :, :, 1], device=device)\n",
    "            vars_ = 1.0 / torch.tensor(step_t_reshaped[:, :, :, 1], device=device)\n",
    "\n",
    "            sarcos_pppoe_means[lz_idx, t, :, :, :] = means.permute(1, 2, 0)\n",
    "            sarcos_pppoe_vars[lz_idx, t, :, :, :]  = vars_.permute(1, 2, 0)\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed = end_time - start_time\n",
    "    times.append(elapsed)\n",
    "    print(f\"Run {repeat + 1} time: {elapsed:.4f} seconds\")\n",
    "\n",
    "# Final summary\n",
    "mean_time = np.mean(times)\n",
    "std_time = np.std(times)\n",
    "print(f\"\\nAverage time over {num_repeats} runs for proposed protocol: {mean_time:.4f} ¬± {std_time:.4f} seconds\")\n",
    "\n",
    "\n",
    "sarcos_rmse_means = torch.zeros((num_Lz, config[\"T\"]+1), device=device)\n",
    "sarcos_rmse_vars = torch.zeros((num_Lz, config[\"T\"]+1), device=device)\n",
    "\n",
    "for lz_idx in range(num_Lz):\n",
    "    for t in range(config[\"T\"]+1):\n",
    "        rmse_means = torch.zeros(config[\"M\"], device=device)\n",
    "        rmse_vars  = torch.zeros(config[\"M\"], device=device)\n",
    "\n",
    "        for m in range(config[\"M\"]):\n",
    "            pred_mean = sarcos_pppoe_means[lz_idx, t, :, :, m] \n",
    "            pred_var  = sarcos_pppoe_vars[lz_idx, t, :, :, m]   \n",
    "            \n",
    "            diff_mean = pred_mean - sarcos_poe_means.to(device)\n",
    "            diff_var  = pred_var  - sarcos_poe_vars.to(device)\n",
    "            \n",
    "            rmse_mean = torch.sqrt(torch.mean(diff_mean ** 2))\n",
    "            rmse_var  = torch.sqrt(torch.mean(diff_var ** 2))\n",
    "\n",
    "            rmse_means[m] = rmse_mean\n",
    "            rmse_vars[m]  = rmse_var\n",
    "            \n",
    "        sarcos_rmse_means[lz_idx, t] = torch.mean(rmse_means)\n",
    "        sarcos_rmse_vars[lz_idx, t] = torch.mean(rmse_vars)\n",
    "\n",
    "for lz_idx in range(num_Lz):\n",
    "    print(f\"Lz index {lz_idx}: RMSE Mean at last iteration = {sarcos_rmse_means[lz_idx, config['T']]:.6f}, \"\n",
    "          f\"RMSE Variance at last iteration = {sarcos_rmse_vars[lz_idx, config['T']]:.6f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e2567f",
   "metadata": {},
   "source": [
    "##### b) Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cc26b269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Run 1/20 ===\n",
      "Running consensus with Lz = 1/10000\n",
      "Run 1 time: 0.1109 seconds\n",
      "\n",
      "=== Run 2/20 ===\n",
      "Running consensus with Lz = 1/10000\n",
      "Run 2 time: 0.1050 seconds\n",
      "\n",
      "=== Run 3/20 ===\n",
      "Running consensus with Lz = 1/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_24812\\1033505841.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  means = torch.tensor(step_t_reshaped[:, :, 0],device=device) / torch.tensor(step_t_reshaped[:, :, 1],device=device)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_24812\\1033505841.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  vars_  = 1.0 / torch.tensor(step_t_reshaped[:, :, 1],device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 3 time: 0.1110 seconds\n",
      "\n",
      "=== Run 4/20 ===\n",
      "Running consensus with Lz = 1/10000\n",
      "Run 4 time: 0.1045 seconds\n",
      "\n",
      "=== Run 5/20 ===\n",
      "Running consensus with Lz = 1/10000\n",
      "Run 5 time: 0.1029 seconds\n",
      "\n",
      "=== Run 6/20 ===\n",
      "Running consensus with Lz = 1/10000\n",
      "Run 6 time: 0.1040 seconds\n",
      "\n",
      "=== Run 7/20 ===\n",
      "Running consensus with Lz = 1/10000\n",
      "Run 7 time: 0.1063 seconds\n",
      "\n",
      "=== Run 8/20 ===\n",
      "Running consensus with Lz = 1/10000\n",
      "Run 8 time: 0.1018 seconds\n",
      "\n",
      "=== Run 9/20 ===\n",
      "Running consensus with Lz = 1/10000\n",
      "Run 9 time: 0.1179 seconds\n",
      "\n",
      "=== Run 10/20 ===\n",
      "Running consensus with Lz = 1/10000\n",
      "Run 10 time: 0.1052 seconds\n",
      "\n",
      "=== Run 11/20 ===\n",
      "Running consensus with Lz = 1/10000\n",
      "Run 11 time: 0.1040 seconds\n",
      "\n",
      "=== Run 12/20 ===\n",
      "Running consensus with Lz = 1/10000\n",
      "Run 12 time: 0.1053 seconds\n",
      "\n",
      "=== Run 13/20 ===\n",
      "Running consensus with Lz = 1/10000\n",
      "Run 13 time: 0.1042 seconds\n",
      "\n",
      "=== Run 14/20 ===\n",
      "Running consensus with Lz = 1/10000\n",
      "Run 14 time: 0.1043 seconds\n",
      "\n",
      "=== Run 15/20 ===\n",
      "Running consensus with Lz = 1/10000\n",
      "Run 15 time: 0.1024 seconds\n",
      "\n",
      "=== Run 16/20 ===\n",
      "Running consensus with Lz = 1/10000\n",
      "Run 16 time: 0.1021 seconds\n",
      "\n",
      "=== Run 17/20 ===\n",
      "Running consensus with Lz = 1/10000\n",
      "Run 17 time: 0.1029 seconds\n",
      "\n",
      "=== Run 18/20 ===\n",
      "Running consensus with Lz = 1/10000\n",
      "Run 18 time: 0.1028 seconds\n",
      "\n",
      "=== Run 19/20 ===\n",
      "Running consensus with Lz = 1/10000\n",
      "Run 19 time: 0.1041 seconds\n",
      "\n",
      "=== Run 20/20 ===\n",
      "Running consensus with Lz = 1/10000\n",
      "Run 20 time: 0.1050 seconds\n",
      "\n",
      "Average time over 20 runs for proposed protocol: 0.1053 ¬± 0.0037 seconds\n",
      "Lz index 0: RMSE Mean at last iteration = 0.017982, RMSE Variance at last iteration = 0.000281\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Lz_values = [10000]\n",
    "num_Lz = len(Lz_values)\n",
    "num_repeats = 20\n",
    "times = []\n",
    "\n",
    "diab_test_samples = diab_X_test.shape[0]\n",
    "\n",
    "for repeat in range(num_repeats):\n",
    "    print(f\"\\n=== Run {repeat + 1}/{num_repeats} ===\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Allocate storage per run\n",
    "    diab_pppoe_means = torch.zeros((num_Lz, config[\"T\"]+1, diab_test_samples, config[\"M\"]), device=device)\n",
    "    diab_pppoe_vars  = torch.zeros((num_Lz, config[\"T\"]+1, diab_test_samples, config[\"M\"]), device=device)\n",
    "\n",
    "    for lz_idx, Lz in enumerate(Lz_values):\n",
    "        print(f\"Running consensus with Lz = 1/{Lz}\")\n",
    "        config[\"Lz\"] = 1.0 / Lz\n",
    "\n",
    "        means_tensor = torch.stack([diab_means[m].to(device) for m in range(config[\"M\"])])  \n",
    "        vars_tensor  = torch.stack([diab_vars[m].to(device) for m in range(config[\"M\"])])  \n",
    "\n",
    "        weighted_means = config[\"M\"] * (means_tensor / vars_tensor)  \n",
    "        precisions = config[\"M\"] * (1.0 / vars_tensor)                \n",
    "\n",
    "        combined = torch.stack([weighted_means, precisions], axis=-1) \n",
    "        z_combined = combined.reshape(config[\"M\"], -1).cpu().numpy() \n",
    "\n",
    "        consensus_history = privacy_preserving_avg_consensus(z_combined, G, config, config[\"T\"]+1, device)\n",
    "\n",
    "        for t in range(config[\"T\"]+1):\n",
    "            step_t = consensus_history[t]  # shape: (M, ntest*2)\n",
    "            step_t_reshaped = step_t.reshape(config[\"M\"], diab_test_samples, 2)\n",
    "\n",
    "            means = torch.tensor(step_t_reshaped[:, :, 0],device=device) / torch.tensor(step_t_reshaped[:, :, 1],device=device) \n",
    "            vars_  = 1.0 / torch.tensor(step_t_reshaped[:, :, 1],device=device)                     \n",
    "\n",
    "            diab_pppoe_means[lz_idx, t] = means.permute(1, 0)\n",
    "            diab_pppoe_vars[lz_idx, t]  = vars_.permute(1, 0)\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed = end_time - start_time\n",
    "    times.append(elapsed)\n",
    "    print(f\"Run {repeat + 1} time: {elapsed:.4f} seconds\")\n",
    "\n",
    "# Summary statistics\n",
    "mean_time = np.mean(times)\n",
    "std_time = np.std(times)\n",
    "print(f\"\\nAverage time over {num_repeats} runs for proposed protocol: {mean_time:.4f} ¬± {std_time:.4f} seconds\")\n",
    "\n",
    "diab_rmse_means = torch.zeros((num_Lz, config[\"T\"]+1), device=device)\n",
    "diab_rmse_vars = torch.zeros((num_Lz, config[\"T\"]+1), device=device)\n",
    "\n",
    "for lz_idx in range(num_Lz):\n",
    "    for t in range(config[\"T\"]+1):\n",
    "        rmse_means = torch.zeros(config[\"M\"], device=device)\n",
    "        rmse_vars = torch.zeros(config[\"M\"], device=device)\n",
    "\n",
    "        for m in range(config[\"M\"]):\n",
    "            pred_mean = diab_pppoe_means[lz_idx, t, :, m] \n",
    "            pred_var  = diab_pppoe_vars[lz_idx, t, :, m]   \n",
    "            \n",
    "            diff_mean = pred_mean - diab_poe_means.to(device)\n",
    "            diff_var = pred_var - diab_poe_vars.to(device)\n",
    "            \n",
    "            rmse_mean = torch.sqrt(torch.mean(diff_mean ** 2))\n",
    "            rmse_var  = torch.sqrt(torch.mean(diff_var ** 2))\n",
    "\n",
    "            rmse_means[m] = rmse_mean\n",
    "            rmse_vars[m]  = rmse_var\n",
    "        diab_rmse_means[lz_idx, t] = torch.mean(rmse_means)\n",
    "        diab_rmse_vars[lz_idx, t] = torch.mean(rmse_vars)\n",
    "\n",
    "for lz_idx in range(num_Lz):\n",
    "    print(f\"Lz index {lz_idx}: RMSE Mean at last iteration = {diab_rmse_means[lz_idx, config['T']]:.6f}, \"\n",
    "          f\"RMSE Variance at last iteration = {diab_rmse_vars[lz_idx, config['T']]:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354ca0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy(sarcos_rmse_means, sarcos_rmse_vars, diab_rmse_means, diab_rmse_vars, config, Lz_values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "26AAAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
